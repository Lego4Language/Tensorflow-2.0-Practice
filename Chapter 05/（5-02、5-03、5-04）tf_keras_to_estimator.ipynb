{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=7, micro=5, releaselevel='final', serial=0)\n",
      "matplotlib 3.1.2\n",
      "numpy 1.17.4\n",
      "pandas 0.25.3\n",
      "sklearn 0.22\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "print(sys.version_info)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 使用pandas读取csv文件并划分数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived     sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0         0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1         1  female  38.0                   1      0  71.2833  First        C   \n",
      "2         1  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3         1  female  35.0                   1      0  53.1000  First        C   \n",
      "4         0    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "   survived     sex   age  n_siblings_spouses  parch     fare   class  \\\n",
      "0         0    male  35.0                   0      0   8.0500   Third   \n",
      "1         0    male  54.0                   0      0  51.8625   First   \n",
      "2         1  female  58.0                   0      0  26.5500   First   \n",
      "3         1  female  55.0                   0      0  16.0000  Second   \n",
      "4         1    male  34.0                   0      0  13.0000  Second   \n",
      "\n",
      "      deck  embark_town alone  \n",
      "0  unknown  Southampton     y  \n",
      "1        E  Southampton     y  \n",
      "2        C  Southampton     y  \n",
      "3  unknown  Southampton     y  \n",
      "4        D  Southampton     y  \n"
     ]
    }
   ],
   "source": [
    "train_file = \"./data/titanic/train.csv\"\n",
    "eval_file = \"./data/titanic/eval.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file)\n",
    "eval_df = pd.read_csv(eval_file)\n",
    "\n",
    "print(train_df.head())  # .head()默认取前5条数据\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      sex   age  n_siblings_spouses  parch     fare  class     deck  \\\n",
      "0    male  22.0                   1      0   7.2500  Third  unknown   \n",
      "1  female  38.0                   1      0  71.2833  First        C   \n",
      "2  female  26.0                   0      0   7.9250  Third  unknown   \n",
      "3  female  35.0                   1      0  53.1000  First        C   \n",
      "4    male  28.0                   0      0   8.4583  Third  unknown   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     n  \n",
      "1    Cherbourg     n  \n",
      "2  Southampton     y  \n",
      "3  Southampton     n  \n",
      "4   Queenstown     y  \n",
      "      sex   age  n_siblings_spouses  parch     fare   class     deck  \\\n",
      "0    male  35.0                   0      0   8.0500   Third  unknown   \n",
      "1    male  54.0                   0      0  51.8625   First        E   \n",
      "2  female  58.0                   0      0  26.5500   First        C   \n",
      "3  female  55.0                   0      0  16.0000  Second  unknown   \n",
      "4    male  34.0                   0      0  13.0000  Second        D   \n",
      "\n",
      "   embark_town alone  \n",
      "0  Southampton     y  \n",
      "1  Southampton     y  \n",
      "2  Southampton     y  \n",
      "3  Southampton     y  \n",
      "4  Southampton     y  \n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    0\n",
      "Name: survived, dtype: int64\n",
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = train_df.pop(\"survived\")\n",
    "y_eval = eval_df.pop(\"survived\")\n",
    "\n",
    "print(train_df.head())\n",
    "print(eval_df.head())\n",
    "print(y_train.head())\n",
    "print(y_eval.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 使用pandas了解数据信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>n_siblings_spouses</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "      <td>627.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.631308</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.379585</td>\n",
       "      <td>34.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.511818</td>\n",
       "      <td>1.151090</td>\n",
       "      <td>0.792999</td>\n",
       "      <td>54.597730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.045800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.387500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age  n_siblings_spouses       parch        fare\n",
       "count  627.000000          627.000000  627.000000  627.000000\n",
       "mean    29.631308            0.545455    0.379585   34.385399\n",
       "std     12.511818            1.151090    0.792999   54.597730\n",
       "min      0.750000            0.000000    0.000000    0.000000\n",
       "25%     23.000000            0.000000    0.000000    7.895800\n",
       "50%     28.000000            0.000000    0.000000   15.045800\n",
       "75%     35.000000            1.000000    0.000000   31.387500\n",
       "max     80.000000            8.000000    5.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(627, 9) (264, 9)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, eval_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c990072d48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.age.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c99217a108>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.sex.value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c992200048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"class\"].value_counts().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex\n",
      "female    0.778802\n",
      "male      0.180488\n",
      "Name: survived, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c992275108>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pd.concat([train_df, y_train], axis=1).groupby(\"sex\").survived.mean())\n",
    "pd.concat([train_df, y_train],                                                            axis=1).groupby(\"sex\").survived.mean().plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用tf.feature_column处理特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sex ['male' 'female']\n",
      "n_siblings_spouses [1 0 3 4 2 5 8]\n",
      "parch [0 1 2 5 3 4]\n",
      "class ['Third' 'First' 'Second']\n",
      "deck ['unknown' 'C' 'G' 'A' 'B' 'D' 'F' 'E']\n",
      "embark_town ['Southampton' 'Cherbourg' 'Queenstown' 'unknown']\n",
      "alone ['n' 'y']\n"
     ]
    }
   ],
   "source": [
    "# tf.feature_column 定义的是处理各列连续和离散数据的规则\n",
    "categorical_columns = [\"sex\", \"n_siblings_spouses\", \"parch\", \"class\", \"deck\",                        \"embark_town\", \"alone\"]\n",
    "numeric_columns = [\"age\", \"fare\"]\n",
    "\n",
    "feature_columns = []\n",
    "# 离散特征处理\n",
    "for categorical_column in categorical_columns:\n",
    "    vocab = train_df[categorical_column].unique()\n",
    "    print(categorical_column, vocab)\n",
    "    feature_columns.append(\n",
    "        # 进行 one-hot 编码\n",
    "        tf.feature_column.indicator_column(      \n",
    "            # 生成 feature_column\n",
    "            tf.feature_column.categorical_column_with_vocabulary_list(                          categorical_column, vocab)))\n",
    "\n",
    "# 连续特征处理\n",
    "for numeric_column in numeric_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(\n",
    "            numeric_column, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(data_df, label_df, epochs=10, shuffle=True, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dict(data_df), label_df))\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(10000)\n",
    "    dataset = dataset.repeat(epochs).batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, y_train, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sex': <tf.Tensor: id=38, shape=(5,), dtype=string, numpy=array([b'male', b'male', b'female', b'male', b'female'], dtype=object)>, 'age': <tf.Tensor: id=30, shape=(5,), dtype=float64, numpy=array([ 7.,  1., 23., 28., 24.])>, 'n_siblings_spouses': <tf.Tensor: id=36, shape=(5,), dtype=int32, numpy=array([4, 4, 0, 0, 0])>, 'parch': <tf.Tensor: id=37, shape=(5,), dtype=int32, numpy=array([1, 1, 0, 0, 0])>, 'fare': <tf.Tensor: id=35, shape=(5,), dtype=float64, numpy=array([39.6875, 39.6875, 13.7917,  7.25  , 69.3   ])>, 'class': <tf.Tensor: id=32, shape=(5,), dtype=string, numpy=array([b'Third', b'Third', b'Second', b'Third', b'First'], dtype=object)>, 'deck': <tf.Tensor: id=33, shape=(5,), dtype=string, numpy=array([b'unknown', b'unknown', b'D', b'unknown', b'B'], dtype=object)>, 'embark_town': <tf.Tensor: id=34, shape=(5,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Cherbourg', b'Southampton',\n",
      "       b'Cherbourg'], dtype=object)>, 'alone': <tf.Tensor: id=31, shape=(5,), dtype=string, numpy=array([b'n', b'n', b'y', b'y', b'y'], dtype=object)>}\n",
      "-------------\n",
      "tf.Tensor([0 0 1 0 1], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataset.take(1):\n",
    "    print(x)\n",
    "    print(\"-------------\")\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer dense_features is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "WARNING:tensorflow:From d:\\python\\installation\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From d:\\python\\installation\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "[[28.      1.      0.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  16.1     1.      0.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [22.      1.      0.      0.      0.      1.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "  29.      1.      0.      0.      0.      0.      0.      0.      0.\n",
      "   1.      0.      0.      0.      0.      0.      1.    ]\n",
      " [29.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      1.      0.      0.      0.\n",
      "   7.775   0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      1.      0.    ]\n",
      " [28.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
      "   7.75    0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]\n",
      " [28.      0.      1.      1.      0.      0.      1.      0.      0.\n",
      "   0.      0.      0.      0.      0.      0.      0.      1.      0.\n",
      "   7.7333  0.      1.      0.      0.      0.      0.      0.      1.\n",
      "   0.      0.      0.      0.      0.      0.      1.    ]]\n"
     ]
    }
   ],
   "source": [
    "# keras.layers.DenseFeatures()将feature_columns里面的规则应用到数据集\n",
    "for x, y in train_dataset.take(1):\n",
    "#     单个特征处理举例\n",
    "#     eg.\n",
    "#     age_column = feature_columns[7]\n",
    "#     gender_column = feature_columns[0]\n",
    "#     print(keras.layers.DenseFeatures(age_column)(x).numpy())\n",
    "#     print(keras.layers.DenseFeatures(gender_column)(x).numpy())\n",
    "\n",
    "    print(keras.layers.DenseFeatures(feature_columns)(x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(2, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 使用model.fit训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 19 steps, validate for 10 steps\n",
      "Epoch 1/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8092 - val_loss: 0.4888 - val_accuracy: 0.7667\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.8109 - val_loss: 0.4808 - val_accuracy: 0.7667\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4437 - accuracy: 0.8109 - val_loss: 0.6151 - val_accuracy: 0.6667\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4194 - accuracy: 0.8207 - val_loss: 0.4631 - val_accuracy: 0.7667\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7862 - val_loss: 0.5034 - val_accuracy: 0.7708\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4068 - accuracy: 0.8273 - val_loss: 0.5011 - val_accuracy: 0.7500\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8059 - val_loss: 0.4691 - val_accuracy: 0.7708\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8158 - val_loss: 0.5105 - val_accuracy: 0.7458\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8076 - val_loss: 0.4590 - val_accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4368 - accuracy: 0.8026 - val_loss: 0.5418 - val_accuracy: 0.7542\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8026 - val_loss: 0.4509 - val_accuracy: 0.7792\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4298 - accuracy: 0.7977 - val_loss: 0.4450 - val_accuracy: 0.7958\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4193 - accuracy: 0.8224 - val_loss: 0.4815 - val_accuracy: 0.7708\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7599 - val_loss: 0.4704 - val_accuracy: 0.7958\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8224 - val_loss: 0.4744 - val_accuracy: 0.7750\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8141 - val_loss: 0.4600 - val_accuracy: 0.7667\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8174 - val_loss: 0.4531 - val_accuracy: 0.7917\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7944 - val_loss: 0.4872 - val_accuracy: 0.7625\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8388 - val_loss: 0.5846 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7961 - val_loss: 0.4883 - val_accuracy: 0.7667\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7977 - val_loss: 0.4663 - val_accuracy: 0.8000\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8141 - val_loss: 0.4489 - val_accuracy: 0.7750\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8240 - val_loss: 0.5302 - val_accuracy: 0.7583\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4136 - accuracy: 0.8174 - val_loss: 0.5127 - val_accuracy: 0.7583\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4350 - accuracy: 0.7895 - val_loss: 0.4694 - val_accuracy: 0.7875\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4108 - accuracy: 0.8174 - val_loss: 0.4633 - val_accuracy: 0.7833\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4176 - accuracy: 0.8158 - val_loss: 0.5319 - val_accuracy: 0.7292\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8010 - val_loss: 0.4932 - val_accuracy: 0.7667\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8174 - val_loss: 0.4488 - val_accuracy: 0.7917\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4034 - accuracy: 0.8257 - val_loss: 0.4825 - val_accuracy: 0.7583\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4530 - accuracy: 0.7944 - val_loss: 0.5162 - val_accuracy: 0.7667\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.8191 - val_loss: 0.4751 - val_accuracy: 0.7833\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4322 - accuracy: 0.7993 - val_loss: 0.4666 - val_accuracy: 0.7667\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7796 - val_loss: 0.4796 - val_accuracy: 0.7708\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8421 - val_loss: 0.5478 - val_accuracy: 0.7083\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.8026 - val_loss: 0.4613 - val_accuracy: 0.7750\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4233 - accuracy: 0.8076 - val_loss: 0.4573 - val_accuracy: 0.7917\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4243 - accuracy: 0.8141 - val_loss: 0.4711 - val_accuracy: 0.7667\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7977 - val_loss: 0.4517 - val_accuracy: 0.7750\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4130 - accuracy: 0.8355 - val_loss: 0.4720 - val_accuracy: 0.7583\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8174 - val_loss: 0.4962 - val_accuracy: 0.7750\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.8141 - val_loss: 0.5216 - val_accuracy: 0.7625\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8405 - val_loss: 0.4704 - val_accuracy: 0.7792\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7944 - val_loss: 0.4252 - val_accuracy: 0.8250\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4093 - accuracy: 0.8289 - val_loss: 0.4274 - val_accuracy: 0.7875\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7993 - val_loss: 0.4516 - val_accuracy: 0.7875\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8059 - val_loss: 0.5159 - val_accuracy: 0.7542\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8273 - val_loss: 0.4362 - val_accuracy: 0.7958\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3937 - accuracy: 0.8191 - val_loss: 0.4849 - val_accuracy: 0.7625\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.8092 - val_loss: 0.4685 - val_accuracy: 0.8083\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8438 - val_loss: 0.4966 - val_accuracy: 0.7708\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4062 - accuracy: 0.8141 - val_loss: 0.4552 - val_accuracy: 0.7792\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7895 - val_loss: 0.4516 - val_accuracy: 0.7750\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8109 - val_loss: 0.4757 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7928 - val_loss: 0.4420 - val_accuracy: 0.8042\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4118 - accuracy: 0.8289 - val_loss: 0.5998 - val_accuracy: 0.7042\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4445 - accuracy: 0.7961 - val_loss: 0.4646 - val_accuracy: 0.7708\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4217 - accuracy: 0.8158 - val_loss: 0.4739 - val_accuracy: 0.7792\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4167 - accuracy: 0.8141 - val_loss: 0.4350 - val_accuracy: 0.7875\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4227 - accuracy: 0.8322 - val_loss: 0.4606 - val_accuracy: 0.7667\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4254 - accuracy: 0.8125 - val_loss: 0.4768 - val_accuracy: 0.7708\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4144 - accuracy: 0.8191 - val_loss: 0.4621 - val_accuracy: 0.8042\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3968 - accuracy: 0.8273 - val_loss: 0.4516 - val_accuracy: 0.7792\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7928 - val_loss: 0.4697 - val_accuracy: 0.7708\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4031 - accuracy: 0.8306 - val_loss: 0.4518 - val_accuracy: 0.7833\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8059 - val_loss: 0.4389 - val_accuracy: 0.7917\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8257 - val_loss: 0.4752 - val_accuracy: 0.7875\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4226 - accuracy: 0.8141 - val_loss: 0.5381 - val_accuracy: 0.7000\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8191 - val_loss: 0.5482 - val_accuracy: 0.7125\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8191 - val_loss: 0.5021 - val_accuracy: 0.7708\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7878 - val_loss: 0.5000 - val_accuracy: 0.7250\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.8059 - val_loss: 0.4695 - val_accuracy: 0.7958\n",
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8207 - val_loss: 0.4645 - val_accuracy: 0.7833\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8339 - val_loss: 0.4782 - val_accuracy: 0.7750\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8191 - val_loss: 0.4489 - val_accuracy: 0.7792\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.8158 - val_loss: 0.4468 - val_accuracy: 0.8000\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8141 - val_loss: 0.4727 - val_accuracy: 0.7917\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.8191 - val_loss: 0.4779 - val_accuracy: 0.7917\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8059 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8273 - val_loss: 0.4723 - val_accuracy: 0.8000\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4468 - accuracy: 0.7911 - val_loss: 0.4438 - val_accuracy: 0.8042\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4090 - accuracy: 0.8191 - val_loss: 0.4619 - val_accuracy: 0.7875\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3930 - accuracy: 0.8207 - val_loss: 0.4757 - val_accuracy: 0.7625\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8207 - val_loss: 0.4753 - val_accuracy: 0.7833\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3912 - accuracy: 0.8405 - val_loss: 0.4655 - val_accuracy: 0.7833\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4129 - accuracy: 0.8273 - val_loss: 0.5263 - val_accuracy: 0.7125\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7993 - val_loss: 0.4653 - val_accuracy: 0.7750\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4120 - accuracy: 0.8306 - val_loss: 0.5160 - val_accuracy: 0.7792\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.7845 - val_loss: 0.4615 - val_accuracy: 0.8083\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.8109 - val_loss: 0.4754 - val_accuracy: 0.7750\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4110 - accuracy: 0.8026 - val_loss: 0.5277 - val_accuracy: 0.7417\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4192 - accuracy: 0.8240 - val_loss: 0.4716 - val_accuracy: 0.7917\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8092 - val_loss: 0.4789 - val_accuracy: 0.7917\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8125 - val_loss: 0.5457 - val_accuracy: 0.7083\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8059 - val_loss: 0.4424 - val_accuracy: 0.8042\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4032 - accuracy: 0.8224 - val_loss: 0.4510 - val_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.8125 - val_loss: 0.4652 - val_accuracy: 0.7792\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4150 - accuracy: 0.8191 - val_loss: 0.4628 - val_accuracy: 0.7958\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8355 - val_loss: 0.4450 - val_accuracy: 0.7958\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8240 - val_loss: 0.4611 - val_accuracy: 0.7625\n"
     ]
    }
   ],
   "source": [
    "train_dataset = make_dataset(train_df, y_train, epochs=100, batch_size=32)\n",
    "eval_dataset = make_dataset(eval_df, y_eval, epochs=1, batch_size=24)\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=eval_dataset,\n",
    "                    steps_per_epoch=19,   # steps_per_epoch <= \n",
    "                             #  num_examples(train_data) // batch_size(train)\n",
    "                    validation_steps=10,    # validation_steps <= \n",
    "              # num_examples(valid_data) * epochs(valid) // batch_size(valid)\n",
    "                    epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 使用estimator训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model -> estimator -> train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\NEO\\AppData\\Local\\Temp\\tmp0sn3arwu\n",
      "INFO:tensorflow:Using the Keras model provided.\n",
      "WARNING:tensorflow:You are creating an Estimator from a Keras model manually subclassed from `Model`, that was already called on some inputs (and thus already had weights). We are currently unable to preserve the model's state (its weights) as part of the estimator in this case. Be warned that the estimator has been created using a freshly initialized version of your model.\n",
      "Note that this doesn't affect the state of the model instance you passed as `keras_model` argument.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\NEO\\\\AppData\\\\Local\\\\Temp\\\\tmp0sn3arwu', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001C9946EE388>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:From d:\\python\\installation\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From d:\\python\\installation\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-269df2597f51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_to_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# 参数input_fn的要求：\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 1. 是一个无参数的函数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 2. 返回值形式如示： a. (features, labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 370\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    371\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1158\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1159\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1160\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1162\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1188\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1189\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1190\u001b[1;33m           features, labels, ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1191\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36mmodel_fn\u001b[1;34m(features, labels, mode)\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m         optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    289\u001b[0m     \u001b[0mmodel_output_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m     \u001b[1;31m# We need to make sure that the output names of the last layer in the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\keras.py\u001b[0m in \u001b[0;36m_clone_and_build_model\u001b[1;34m(mode, keras_model, custom_objects, features, labels, optimizer_config)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[0min_place_reset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mkeras_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0moptimizer_iterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m       optimizer_config=optimizer_config)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0msample_weight_tensors\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_and_build_model\u001b[1;34m(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m       \u001b[0mclone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     if all([isinstance(clone, Sequential),\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36mclone_model\u001b[1;34m(model, input_tensors, clone_function)\u001b[0m\n\u001b[0;32m    417\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     return _clone_sequential_model(\n\u001b[1;32m--> 419\u001b[1;33m         model, input_tensors=input_tensors, layer_fn=clone_function)\n\u001b[0m\u001b[0;32m    420\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     return _clone_functional_model(\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\u001b[0m in \u001b[0;36m_clone_sequential_model\u001b[1;34m(model, input_tensors, layer_fn)\u001b[0m\n\u001b[0;32m    336\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_keras_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m       \u001b[0morigin_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keras_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\installation\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mis_keras_tensor\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    985\u001b[0m                         sparse_tensor.SparseTensor)):\n\u001b[0;32m    986\u001b[0m     raise ValueError('Unexpectedly found an instance of type `' + str(type(x)) +\n\u001b[1;32m--> 987\u001b[1;33m                      '`. Expected a symbolic tensor instance.')\n\u001b[0m\u001b[0;32m    988\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_keras_history'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpectedly found an instance of type `<class 'dict'>`. Expected a symbolic tensor instance."
     ]
    }
   ],
   "source": [
    "estimator = keras.estimator.model_to_estimator(model)\n",
    "estimator.train(input_fn=lambda : make_dataset(train_df, y_train, epochs=100))\n",
    "# 参数input_fn的要求：\n",
    "# 1. 是一个无参数的函数\n",
    "# 2. 返回值形式如示： a. (features, labels)\n",
    "#                    b. dataset -> (features, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
