{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.17.4\n",
      "pandas 0.25.3\n",
      "sklearn 0.22\n",
      "matplotlib 3.1.2\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n",
      "sys.version_info(major=3, minor=7, micro=5, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pprint import pprint\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "for module in np, pd, sklearn, mpl, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 1.获取并处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "('First Citizen:\\n'\n",
      " 'Before we proceed any further, hear me speak.\\n'\n",
      " '\\n'\n",
      " 'All:\\n'\n",
      " 'Speak, speak.\\n'\n",
      " '\\n'\n",
      " 'First Citizen:\\n'\n",
      " 'You')\n"
     ]
    }
   ],
   "source": [
    "input_filepath = \"./shakespeare.txt\"\n",
    "\n",
    "with open(input_filepath, \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(len(text))\n",
    "pprint(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 生成词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] 65\n"
     ]
    }
   ],
   "source": [
    "vocab =sorted(set(text))  # 给字符排序\n",
    "print(vocab, len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 构造词表映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
      "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
      " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "# build mapping char -> id\n",
    "char2idx = {char:idx for idx, char in enumerate(vocab)}\n",
    "print(char2idx)\n",
    "\n",
    "idx2char = np.array(vocab)\n",
    "print(idx2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 将文本数据集转换为ID数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 47 56 57 58  1 15 47 58 47]\n",
      "First Citi\n"
     ]
    }
   ],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "print(text_as_int[:10])\n",
    "print(text[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 将ID数据集转为dataset，并设定句子长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18, shape=(), dtype=int32) F\n",
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1], shape=(101,), dtype=int32)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "seq_length = 100   # 设置句子长度（并不是以自然的句子方式结尾，而是限定长度）\n",
    "seq_dataset = char_dataset.batch(\n",
    "    seq_length+1, # 训练集与目标集要错一位进行预测\n",
    "    drop_remainder=True)  # 最后一批如果长度不满足seq_length + 1则舍去\n",
    "\n",
    "for ch_id in char_dataset.take(1):\n",
    "    print(ch_id, idx2char[ch_id.numpy()])\n",
    "    \n",
    "for seq_id in seq_dataset.take(1):\n",
    "    print(seq_id)\n",
    "    print(repr(\"\".join(idx2char[seq_id.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 划分数据集为train_data和_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59]\n",
      "Output: \n",
      "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
      " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
      "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
      " 37 53 59  1]\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(id_text):\n",
    "    \"\"\" abcde -> abcd(input), bcde(output) \"\"\"\n",
    "    return id_text[0:-1], id_text[1:]\n",
    "\n",
    "seq_dataset = seq_dataset.map(split_input_target)\n",
    "\n",
    "for item in seq_dataset.take(1): # 解包\n",
    "    print(\"Input: \")\n",
    "    print(item[0].numpy())\n",
    "    print(\"Output: \")\n",
    "    print(item[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=61, shape=(64, 100), dtype=int32, numpy=\n",
      "array([[ 6,  1, 50, ..., 43,  8,  1],\n",
      "       [ 1, 58, 46, ..., 51, 39, 52],\n",
      "       [53, 52, 43, ..., 15, 17, 31],\n",
      "       ...,\n",
      "       [26, 33, 31, ..., 57, 57,  8],\n",
      "       [ 1, 57, 58, ..., 42, 53, 52],\n",
      "       [46,  1, 53, ..., 53, 58, 46]])>, <tf.Tensor: id=62, shape=(64, 100), dtype=int32, numpy=\n",
      "array([[ 1, 50, 43, ...,  8,  1, 35],\n",
      "       [58, 46, 39, ..., 39, 52, 42],\n",
      "       [52, 43,  0, ..., 17, 31, 32],\n",
      "       ...,\n",
      "       [33, 31, 10, ..., 57,  8,  0],\n",
      "       [57, 58, 39, ..., 53, 52,  1],\n",
      "       [ 1, 53, 52, ..., 58, 46, 47]])>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "\n",
    "seq_dataset = seq_dataset.shuffle(buffer_size).batch(\n",
    "    batch_size, drop_remainder=True)\n",
    "\n",
    "for item in seq_dataset.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 2. RNN建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 256)         16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, None, 200)         91400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 65)          13065     \n",
      "=================================================================\n",
      "Total params: 121,105\n",
      "Trainable params: 121,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 200\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size,\n",
    "                               embedding_dim,),\n",
    "#                                batch_input_shape=[batch_size, None]),\n",
    "        keras.layers.SimpleRNN(units=rnn_units,\n",
    "                               return_sequences=True),\n",
    "        keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(vocab_size=vocab_size,\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 使用初始模型进行预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in seq_dataset.take(1):\n",
    "    # 利用初始化的模型进行预测\n",
    "    example_batch_predictions = model(input_example_batch)  \n",
    "    print(example_batch_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[54]\n",
      " [28]\n",
      " [46]\n",
      " [49]\n",
      " [ 8]\n",
      " [32]\n",
      " [20]\n",
      " [52]\n",
      " [60]\n",
      " [49]\n",
      " [64]\n",
      " [22]\n",
      " [13]\n",
      " [55]\n",
      " [13]\n",
      " [47]\n",
      " [55]\n",
      " [57]\n",
      " [24]\n",
      " [42]\n",
      " [32]\n",
      " [14]\n",
      " [54]\n",
      " [57]\n",
      " [31]\n",
      " [19]\n",
      " [43]\n",
      " [31]\n",
      " [63]\n",
      " [24]\n",
      " [13]\n",
      " [ 5]\n",
      " [ 2]\n",
      " [38]\n",
      " [49]\n",
      " [42]\n",
      " [62]\n",
      " [14]\n",
      " [49]\n",
      " [52]\n",
      " [54]\n",
      " [13]\n",
      " [ 7]\n",
      " [15]\n",
      " [64]\n",
      " [38]\n",
      " [40]\n",
      " [48]\n",
      " [29]\n",
      " [59]\n",
      " [43]\n",
      " [53]\n",
      " [27]\n",
      " [60]\n",
      " [49]\n",
      " [33]\n",
      " [48]\n",
      " [57]\n",
      " [14]\n",
      " [14]\n",
      " [52]\n",
      " [51]\n",
      " [13]\n",
      " [47]\n",
      " [54]\n",
      " [32]\n",
      " [58]\n",
      " [30]\n",
      " [16]\n",
      " [64]\n",
      " [29]\n",
      " [38]\n",
      " [22]\n",
      " [28]\n",
      " [41]\n",
      " [ 0]\n",
      " [10]\n",
      " [63]\n",
      " [60]\n",
      " [27]\n",
      " [39]\n",
      " [19]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [22]\n",
      " [54]\n",
      " [18]\n",
      " [ 3]\n",
      " [58]\n",
      " [ 4]\n",
      " [32]\n",
      " [32]\n",
      " [55]\n",
      " [40]\n",
      " [26]\n",
      " [ 2]\n",
      " [57]\n",
      " [21]\n",
      " [26]\n",
      " [63]], shape=(100, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[54 28 46 49  8 32 20 52 60 49 64 22 13 55 13 47 55 57 24 42 32 14 54 57\n",
      " 31 19 43 31 63 24 13  5  2 38 49 42 62 14 49 52 54 13  7 15 64 38 40 48\n",
      " 29 59 43 53 27 60 49 33 48 57 14 14 52 51 13 47 54 32 58 30 16 64 29 38\n",
      " 22 28 41  0 10 63 60 27 39 19  8  9 22 54 18  3 58  4 32 32 55 40 26  2\n",
      " 57 21 26 63], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# random sampling\n",
    "# greedy, random 贪心采样与随机采样\n",
    "# (100, 65) -> (100, 1)\n",
    "# tf.random.categorical输入维度必须为二维\n",
    "sample_indices = tf.random.categorical(logits=example_batch_predictions[0],\n",
    "                                       num_samples=1)\n",
    "print(sample_indices)   \n",
    "sample_indices = tf.squeeze(sample_indices, axis=-1)\n",
    "print(sample_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  ' temper with the stars:\\nYet in this one thing let me blame your grace,\\nFor choosing me when Clarence'\n",
      "\n",
      "Output:  'temper with the stars:\\nYet in this one thing let me blame your grace,\\nFor choosing me when Clarence '\n",
      "\n",
      "Prediction:  \"pPhk.THnvkzJAqAiqsLdTBpsSGeSyLA'!ZkdxBknpA-CzZbjQueoOvkUjsBBnmAipTtRDzQZJPc\\n:yvOaG.3JpF$t&TTqbN!sINy\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Output: \", repr(\"\".join(idx2char[target_example_batch[0]])))\n",
    "print()\n",
    "print(\"Prediction: \", repr(\"\".join(idx2char[sample_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "(64, 100, 65)\n",
      "(64, 100)\n",
      "4.188471\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(\n",
    "        labels,\n",
    "        logits,\n",
    "        from_logits=True) # 最后一层神经网络中没有激活函数softmax，\n",
    "                          # 所以不是归一化形式\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=loss)\n",
    "example_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(target_example_batch.shape)\n",
    "print(example_batch_predictions.shape)\n",
    "print(example_loss.shape)\n",
    "print(example_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "172/172 [==============================] - 20s 115ms/step - loss: 2.6116\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 21s 122ms/step - loss: 2.0878\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 20s 114ms/step - loss: 1.9268\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 1.8274\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 1.7593\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 1.7106\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 18s 107ms/step - loss: 1.6718\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 19s 108ms/step - loss: 1.6418\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 1.6168\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.5963\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.5787\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 16s 96ms/step - loss: 1.5640\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.5506\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.5389\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.5290\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 1.5190\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 1.5105\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.5040\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.4963\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.4905\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 18s 104ms/step - loss: 1.4843\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.4791\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 18s 106ms/step - loss: 1.4739\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 18s 104ms/step - loss: 1.4693\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 17s 102ms/step - loss: 1.4649\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.4609\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 17s 102ms/step - loss: 1.4568\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.4526\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 17s 102ms/step - loss: 1.4499\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.4471\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.4433\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.4413\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.4381\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.4354\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.4334\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.4308\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.4287\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.4261\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.4245\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.4225\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.4208\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.4190\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.4172\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.4152\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.4137\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 1.4121\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.4112\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.41000s - loss: 1.41\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.4076 1\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.4066 0s - loss: 1\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 17s 102ms/step - loss: 1.4053\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.4044\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.4025\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 1.4014\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.4001\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.3993 ETA\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.3983\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3970\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.3959\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 17s 97ms/step - loss: 1.3955\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.3944\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3934\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3925\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3916\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.39030s - loss: 1.\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3900\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.3887\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 1.3884\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3875\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.3875\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.38631s -\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.3851\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.3848 0s - los\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3835\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3838\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3820\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3813\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3809\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.3808\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3800\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.3789\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.3789\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.3783\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3774ETA: \n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 18s 102ms/step - loss: 1.3774\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.3764\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3762\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3753\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.3751\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.3746\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3742\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 17s 100ms/step - loss: 1.3734\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 1.3731\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 17s 98ms/step - loss: 1.3730\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3724\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3721\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 17s 99ms/step - loss: 1.3717\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 1.3710\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 17s 101ms/step - loss: 1.3707\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 18s 103ms/step - loss: 1.3701\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./text_generation_checkpoints\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "# 使用多个checkpoint文件记录每个epoch中的参数值，以前只用checkpoint记录所有\n",
    "# epoch中效果最好的模型，并且把参数记录在一个h5文件中，这里有所不同\n",
    "checkpoint_prefix = os.path.join(output_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "epochs = 100\n",
    "history = model.fit(seq_dataset, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.history.keys()\n",
    "def plot_loss_curves(history):\n",
    "    plt.plot(range(epochs), history.history[\"loss\"])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用checkpoint载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./text_generation_checkpoints\\ckpt_100\n"
     ]
    }
   ],
   "source": [
    "print(tf.train.latest_checkpoint(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 256)         16640     \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, None, 200)         91400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 65)          13065     \n",
      "=================================================================\n",
      "Total params: 121,105\n",
      "Trainable params: 121,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model(vocab_size,\n",
    "                     embedding_dim,\n",
    "                     rnn_units,\n",
    "                     batch_size=1)\n",
    "model2.load_weights(tf.train.latest_checkpoint(output_dir))\n",
    "model2.build(tf.TensorShape([1, None])) # model2.build([1, None])\n",
    "                                        # 输入是一个变长\n",
    "# start ch sequence A,\n",
    "# A -> model -> b\n",
    "# A.append(b) -> B\n",
    "# B(Ab) -> model -> c\n",
    "# b.append(c) -> C\n",
    "# C(Abc) -> model -> ...\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: your' h d t JORDIZo r'linging h, n Myongoce a wes ur me; hean I thow han hang d thoulor gg s m? mond phe. am co has d le bus, y. binou t, hante cerame scke weandonty lons,\n",
      "CES fldlokethandabser g gra we wes!\n",
      "USThinwhan st t w ase we heambomomit tas uthy,\n",
      "\n",
      "Ift tr t wer thend my in.\n",
      "VO:\n",
      "ANUplyo I he ge thato ththickepondotholulon G uspt.\n",
      "AUS:\n",
      "Butlly cked stly thatt,\n",
      "Whow f w Amivon't in f prinopithouthend; pece mocomin athathit tony bulerodeard atud cous merath h thirse,\n",
      "STR rdeved\n",
      "athan,\n",
      "An;\n",
      "SThe urescy ge I th, thouly't.\n",
      "That wicke fit fe! benote w m\n",
      "\n",
      "CUSevell d?\n",
      "Me!\n",
      "BYO, mut t, at t no,\n",
      "Fofus r, aker, are yo ind thit.\n",
      "I atoche\n",
      "D:\n",
      "RO:\n",
      "bont IOLIZAREThatinowivican a g witr?\n",
      "ARilicknoran\n",
      "IULA:\n",
      "QUSo fut t, ath nichan hirs Pered lack theave thalulithacus t ir be spe s, or e e;\n",
      "TRULAs areveyowanacheday tey;\n",
      "BUCLLI: d hasttlust t borane; wnd blo s marithas,\n",
      "A:\n",
      "Lowan m f hasenth\n",
      "TARUCLO, an ldivy weve! pr te, r t myo INeysomit PENTouphean r! t s\n",
      "\n",
      "I ghy onge ant s, Whe thafuler?\n",
      "CA:\n",
      "K:\n",
      "\n",
      "CLO, lu\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string, num_generate=1000):\n",
    "    input_eval = [char2idx[ch] for ch in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, axis=0)\n",
    "    \n",
    "    text_generated = []\n",
    "    model.reset_states()     # ???????????\n",
    "    \n",
    "    for _ in range(num_generate):\n",
    "        # 1. model inderence -> predictions\n",
    "        # 2. sample -> ch -> text_generated.\n",
    "        # 3. update input_eval\n",
    "        \n",
    "        # predictions : [batch_size, input_eval_len, vocab_size]\n",
    "        predictions = model(input_eval)\n",
    "        # predictions : [input_eval_len, vocab_size]\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # prediction_ids: [input_eval_len, 1]\n",
    "        # a b c -> b c d\n",
    "        prediction_id = tf.random.categorical(predictions,\n",
    "                                              num_samples=1)[-1, 0].numpy()\n",
    "        text_generated.append(idx2char[prediction_id])\n",
    "        input_eval = tf.expand_dims([prediction_id], 0)\n",
    "    return start_string + \"\".join(text_generated)\n",
    "\n",
    "new_text = generate_text(model2, \"All: \")\n",
    "print(new_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
