{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy 1.17.4\n",
      "pandas 0.25.3\n",
      "sklearn 0.22\n",
      "matplotlib 3.1.2\n",
      "tensorflow 2.0.0\n",
      "tensorflow_core.keras 2.2.4-tf\n",
      "sys.version_info(major=3, minor=7, micro=5, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from pprint import pprint\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "for module in np, pd, sklearn, mpl, tf, keras:\n",
    "    print(module.__name__, module.__version__)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 1.获取并处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115394\n",
      "('First Citizen:\\n'\n",
      " 'Before we proceed any further, hear me speak.\\n'\n",
      " '\\n'\n",
      " 'All:\\n'\n",
      " 'Speak, speak.\\n'\n",
      " '\\n'\n",
      " 'First Citizen:\\n'\n",
      " 'You')\n"
     ]
    }
   ],
   "source": [
    "input_filepath = \"./shakespeare.txt\"\n",
    "\n",
    "with open(input_filepath, \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(len(text))\n",
    "pprint(text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 生成词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] 65\n"
     ]
    }
   ],
   "source": [
    "vocab =sorted(set(text))  # 给字符排序\n",
    "print(vocab, len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 构造词表映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'\\n': 0, ' ': 1, '!': 2, '$': 3, '&': 4, \"'\": 5, ',': 6, '-': 7, '.': 8, '3': 9, ':': 10, ';': 11, '?': 12, 'A': 13, 'B': 14, 'C': 15, 'D': 16, 'E': 17, 'F': 18, 'G': 19, 'H': 20, 'I': 21, 'J': 22, 'K': 23, 'L': 24, 'M': 25, 'N': 26, 'O': 27, 'P': 28, 'Q': 29, 'R': 30, 'S': 31, 'T': 32, 'U': 33, 'V': 34, 'W': 35, 'X': 36, 'Y': 37, 'Z': 38, 'a': 39, 'b': 40, 'c': 41, 'd': 42, 'e': 43, 'f': 44, 'g': 45, 'h': 46, 'i': 47, 'j': 48, 'k': 49, 'l': 50, 'm': 51, 'n': 52, 'o': 53, 'p': 54, 'q': 55, 'r': 56, 's': 57, 't': 58, 'u': 59, 'v': 60, 'w': 61, 'x': 62, 'y': 63, 'z': 64}\n",
      "['\\n' ' ' '!' '$' '&' \"'\" ',' '-' '.' '3' ':' ';' '?' 'A' 'B' 'C' 'D' 'E'\n",
      " 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V' 'W'\n",
      " 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o'\n",
      " 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
     ]
    }
   ],
   "source": [
    "# build mapping char -> id\n",
    "char2idx = {char:idx for idx, char in enumerate(vocab)}\n",
    "print(char2idx)\n",
    "\n",
    "idx2char = np.array(vocab)\n",
    "print(idx2char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 将文本数据集转换为ID数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18 47 56 57 58  1 15 47 58 47]\n",
      "First Citi\n"
     ]
    }
   ],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "print(text_as_int[:10])\n",
    "print(text[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 将ID数据集转为dataset，并设定句子长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(18, shape=(), dtype=int32) F\n",
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1], shape=(101,), dtype=int32)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "seq_length = 100   # 设置句子长度（并不是以自然的句子方式结尾，而是限定长度）\n",
    "seq_dataset = char_dataset.batch(\n",
    "    seq_length+1, # 训练集与目标集要错一位进行预测\n",
    "    drop_remainder=True)  # 最后一批如果长度不满足seq_length + 1则舍去\n",
    "\n",
    "for ch_id in char_dataset.take(1):\n",
    "    print(ch_id, idx2char[ch_id.numpy()])\n",
    "    \n",
    "for seq_id in seq_dataset.take(1):\n",
    "    print(seq_id)\n",
    "    print(repr(\"\".join(idx2char[seq_id.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 划分数据集为train_data和_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59]\n",
      "Output: \n",
      "[47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43  1\n",
      " 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43 39\n",
      " 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49  6\n",
      "  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0\n",
      " 37 53 59  1]\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(id_text):\n",
    "    \"\"\" abcde -> abcd(input), bcde(output) \"\"\"\n",
    "    return id_text[0:-1], id_text[1:]\n",
    "\n",
    "seq_dataset = seq_dataset.map(split_input_target)\n",
    "\n",
    "for item in seq_dataset.take(1): # 解包\n",
    "    print(\"Input: \")\n",
    "    print(item[0].numpy())\n",
    "    print(\"Output: \")\n",
    "    print(item[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: id=61, shape=(64, 100), dtype=int32, numpy=\n",
      "array([[63,  1, 42, ..., 43, 61, 57],\n",
      "       [30, 21, 34, ...,  1, 46, 39],\n",
      "       [42,  1, 58, ..., 63, 53, 59],\n",
      "       ...,\n",
      "       [57, 47, 52, ..., 42, 53, 53],\n",
      "       [ 1, 57, 53, ..., 53, 52,  1],\n",
      "       [52,  1, 51, ..., 56, 43,  5]])>, <tf.Tensor: id=62, shape=(64, 100), dtype=int32, numpy=\n",
      "array([[ 1, 42, 53, ..., 61, 57, 12],\n",
      "       [21, 34, 17, ..., 46, 39, 52],\n",
      "       [ 1, 58, 53, ..., 53, 59,  1],\n",
      "       ...,\n",
      "       [47, 52, 41, ..., 53, 53, 56],\n",
      "       [57, 53, 53, ..., 52,  1, 58],\n",
      "       [ 1, 51, 63, ..., 43,  5, 57]])>)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "buffer_size = 10000\n",
    "\n",
    "seq_dataset = seq_dataset.shuffle(buffer_size).batch(\n",
    "    batch_size, drop_remainder=True)\n",
    "\n",
    "for item in seq_dataset.take(1):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## 2. RNN建模"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           16640     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (64, None, 200)           365600    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 65)            13065     \n",
      "=================================================================\n",
      "Total params: 395,305\n",
      "Trainable params: 395,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 200\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Embedding(vocab_size,\n",
    "                               embedding_dim,\n",
    "                               batch_input_shape=[batch_size, None]),\n",
    "        keras.layers.LSTM(units=rnn_units,\n",
    "                          stateful=True,\n",
    "                          recurrent_initializer=\"glorot_uniform\",\n",
    "                          return_sequences=True),\n",
    "        keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_model(vocab_size=vocab_size,\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    rnn_units=rnn_units,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 使用初始模型进行预测 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 65)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in seq_dataset.take(1):\n",
    "    # 利用初始化的模型进行预测\n",
    "    example_batch_predictions = model(input_example_batch)  \n",
    "    print(example_batch_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[60]\n",
      " [45]\n",
      " [31]\n",
      " [54]\n",
      " [17]\n",
      " [50]\n",
      " [20]\n",
      " [ 4]\n",
      " [13]\n",
      " [ 6]\n",
      " [30]\n",
      " [51]\n",
      " [23]\n",
      " [18]\n",
      " [ 9]\n",
      " [32]\n",
      " [29]\n",
      " [36]\n",
      " [38]\n",
      " [51]\n",
      " [ 5]\n",
      " [31]\n",
      " [54]\n",
      " [64]\n",
      " [30]\n",
      " [64]\n",
      " [48]\n",
      " [50]\n",
      " [23]\n",
      " [58]\n",
      " [42]\n",
      " [24]\n",
      " [14]\n",
      " [15]\n",
      " [ 8]\n",
      " [17]\n",
      " [ 0]\n",
      " [46]\n",
      " [48]\n",
      " [32]\n",
      " [20]\n",
      " [17]\n",
      " [53]\n",
      " [24]\n",
      " [16]\n",
      " [53]\n",
      " [41]\n",
      " [34]\n",
      " [ 4]\n",
      " [59]\n",
      " [32]\n",
      " [28]\n",
      " [48]\n",
      " [ 1]\n",
      " [10]\n",
      " [ 6]\n",
      " [49]\n",
      " [ 1]\n",
      " [62]\n",
      " [35]\n",
      " [ 1]\n",
      " [12]\n",
      " [24]\n",
      " [12]\n",
      " [ 2]\n",
      " [34]\n",
      " [24]\n",
      " [38]\n",
      " [48]\n",
      " [ 7]\n",
      " [41]\n",
      " [36]\n",
      " [ 7]\n",
      " [39]\n",
      " [34]\n",
      " [31]\n",
      " [35]\n",
      " [47]\n",
      " [22]\n",
      " [59]\n",
      " [23]\n",
      " [51]\n",
      " [18]\n",
      " [31]\n",
      " [34]\n",
      " [ 1]\n",
      " [58]\n",
      " [10]\n",
      " [50]\n",
      " [56]\n",
      " [51]\n",
      " [12]\n",
      " [56]\n",
      " [38]\n",
      " [40]\n",
      " [43]\n",
      " [26]\n",
      " [41]\n",
      " [52]\n",
      " [54]], shape=(100, 1), dtype=int64)\n",
      "tf.Tensor(\n",
      "[60 45 31 54 17 50 20  4 13  6 30 51 23 18  9 32 29 36 38 51  5 31 54 64\n",
      " 30 64 48 50 23 58 42 24 14 15  8 17  0 46 48 32 20 17 53 24 16 53 41 34\n",
      "  4 59 32 28 48  1 10  6 49  1 62 35  1 12 24 12  2 34 24 38 48  7 41 36\n",
      "  7 39 34 31 35 47 22 59 23 51 18 31 34  1 58 10 50 56 51 12 56 38 40 43\n",
      " 26 41 52 54], shape=(100,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# random sampling\n",
    "# greedy, random 贪心采样与随机采样\n",
    "# (100, 65) -> (100, 1)\n",
    "# tf.random.categorical输入维度必须为二维\n",
    "sample_indices = tf.random.categorical(logits=example_batch_predictions[0],\n",
    "                                       num_samples=1)\n",
    "print(sample_indices)   \n",
    "sample_indices = tf.squeeze(sample_indices, axis=-1)\n",
    "print(sample_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  ', I spy some pity in thy looks:\\nO, if thine eye be not a flatterer,\\nCome thou on my side, and entrea'\n",
      "\n",
      "Output:  ' I spy some pity in thy looks:\\nO, if thine eye be not a flatterer,\\nCome thou on my side, and entreat'\n",
      "\n",
      "Prediction:  \"vgSpElH&A,RmKF3TQXZm'SpzRzjlKtdLBC.E\\nhjTHEoLDocV&uTPj :,k xW ?L?!VLZj-cX-aVSWiJuKmFSV t:lrm?rZbeNcnp\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Output: \", repr(\"\".join(idx2char[target_example_batch[0]])))\n",
    "print()\n",
    "print(\"Prediction: \", repr(\"\".join(idx2char[sample_indices])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100)\n",
      "(64, 100, 65)\n",
      "(64, 100)\n",
      "4.174729\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return keras.losses.sparse_categorical_crossentropy(\n",
    "        labels,\n",
    "        logits,\n",
    "        from_logits=True) # 最后一层神经网络中没有激活函数softmax，\n",
    "                          # 所以不是归一化形式\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=loss)\n",
    "example_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(target_example_batch.shape)\n",
    "print(example_batch_predictions.shape)\n",
    "print(example_loss.shape)\n",
    "print(example_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 49s 287ms/step - loss: 2.8063\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 51s 297ms/step - loss: 2.1752\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 55s 322ms/step - loss: 1.9973\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 59s 346ms/step - loss: 1.8886\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 58s 337ms/step - loss: 1.8115\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 57s 333ms/step - loss: 1.7538\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 59s 340ms/step - loss: 1.7084\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 60s 347ms/step - loss: 1.6731\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 60s 348ms/step - loss: 1.6428\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 59s 342ms/step - loss: 1.6168\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"./text_generation_checkpoints\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "# 使用多个checkpoint文件记录每个epoch中的参数值，以前只用checkpoint记录所有\n",
    "# epoch中效果最好的模型，并且把参数记录在一个h5文件中，这里有所不同\n",
    "checkpoint_prefix = os.path.join(output_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "epochs = 10\n",
    "history = model.fit(seq_dataset, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history.history.keys()\n",
    "def plot_loss_curves(history):\n",
    "    plt.plot(range(epochs), history.history[\"loss\"])\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_curves(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 使用checkpoint载入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./text_generation_checkpoints\\ckpt_10\n"
     ]
    }
   ],
   "source": [
    "print(tf.train.latest_checkpoint(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            16640     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (1, None, 200)            365600    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 65)             13065     \n",
      "=================================================================\n",
      "Total params: 395,305\n",
      "Trainable params: 395,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model(vocab_size,\n",
    "                     embedding_dim,\n",
    "                     rnn_units,\n",
    "                     batch_size=1)\n",
    "model2.load_weights(tf.train.latest_checkpoint(output_dir))\n",
    "model2.build(tf.TensorShape([1, None])) # model2.build([1, None])\n",
    "                                        # 输入是一个变长\n",
    "# start ch sequence A,\n",
    "# A -> model -> b\n",
    "# A.append(b) -> B\n",
    "# B(Ab) -> model -> c\n",
    "# b.append(c) -> C\n",
    "# C(Abc) -> model -> ...\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All: here do the hands, he and you deeming to and come:\n",
      "If the compersed to my sugen and father\n",
      "That shall the wind the chast of honour with a faure.\n",
      "\n",
      "BIONDELLO:\n",
      "I to my say the comes to be death,\n",
      "And set the proud in the vein the sinds some street the of your great strock\n",
      "To you will gable of my lag to men him:\n",
      "The seech the court and the worst the dest of a bear and did as be the made of the shall have be enough to have\n",
      "The plack is strain must the last the erest, and they son my for the mouth,\n",
      "Where it marrichion of the for they hast\n",
      "The rear of your treet love the father,\n",
      "The bear the many son my strong the fortune to be to so still prince,\n",
      "In the could not in the shall be true thee and matter man,\n",
      "What the bore the mean the should not this love.\n",
      "\n",
      "CAMILLO:\n",
      "I that the shall than the pasting and here.\n",
      "\n",
      "LADY CAPULET:\n",
      "What you the such a more that see such advice me a light.\n",
      "\n",
      "BRUTUS:\n",
      "Nor chart our mind me here and pleased to suce\n",
      "That the life, sir, the parter of chires\n",
      "To make that I see t\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string, num_generate=1000):\n",
    "    input_eval = [char2idx[ch] for ch in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, axis=0)\n",
    "    \n",
    "    text_generated = []\n",
    "    model.reset_states()     # ???????????\n",
    "    \n",
    "    # temperature > 1, random \n",
    "    # temperature < 1, greedy\n",
    "    temperature = 0.5\n",
    "    \n",
    "    for _ in range(num_generate):\n",
    "        # 1. model inderence -> predictions\n",
    "        # 2. sample -> ch -> text_generated.\n",
    "        # 3. update input_eval\n",
    "        \n",
    "        # predictions : [batch_size, input_eval_len, vocab_size]\n",
    "        predictions = model(input_eval)\n",
    "        # predicions: logits -> softmax -> prob\n",
    "        # softmax: e^xi\n",
    "        # eg: 4, 2   e^4/(e^4 + e^2) = 0.88, e^2/(e^4 + e^2) = 0.12\n",
    "        # eg: 2, 1   e^2/(e^2 + e) = 0.73, e/(e^2 + e) = 0.27\n",
    "        predictions = predictions / temperature\n",
    "        # predictions : [input_eval_len, vocab_size]\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # prediction_ids: [input_eval_len, 1]\n",
    "        # a b c -> b c d\n",
    "        prediction_id = tf.random.categorical(predictions,\n",
    "                                              num_samples=1)[-1, 0].numpy()\n",
    "        text_generated.append(idx2char[prediction_id])\n",
    "        input_eval = tf.expand_dims([prediction_id], 0)\n",
    "    return start_string + \"\".join(text_generated)\n",
    "\n",
    "new_text = generate_text(model2, \"All: \")\n",
    "print(new_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
